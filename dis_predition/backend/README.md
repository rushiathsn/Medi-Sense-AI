# MediSense AI - Backend Setup Guide

## ğŸ“ Backend Structure

```
backend/
â”œâ”€â”€ app.py                  # Flask API server
â”œâ”€â”€ train_model.py          # ML model training script
â”œâ”€â”€ create_dataset.py       # Dataset generation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ data/                   # Data directory
â”‚   â”œâ”€â”€ training_data.csv   # Generated training data
â”‚   â””â”€â”€ disease_info.pkl    # Disease information
â””â”€â”€ model/                  # Trained models
    â”œâ”€â”€ disease_predictor.pkl
    â”œâ”€â”€ symptom_vectorizer.pkl
    â””â”€â”€ disease_info.pkl
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd backend
pip install -r requirements.txt
```

**Required packages:**
- Flask (web framework)
- Flask-CORS (enable frontend access)
- scikit-learn (machine learning)
- pandas (data processing)
- numpy (numerical operations)
- joblib (model serialization)

### 2. Create Training Dataset

```bash
python create_dataset.py
```

This will:
- Generate training data for 24 diseases
- Create 120+ training samples
- Save disease information database
- Output: `data/training_data.csv` and `data/disease_info.pkl`

### 3. Train the ML Model

```bash
python train_model.py
```

This will:
- Load training data
- Train Random Forest classifier
- Evaluate model performance
- Save trained model to `model/` directory
- Test with sample predictions

**Expected output:**
```
âœ“ Training accuracy: ~95%
âœ“ Test accuracy: ~85-90%
âœ“ Cross-validation accuracy: ~87%
```

### 4. Start Backend Server

```bash
python app.py
```

Server will start on: `http://localhost:5000`

## ğŸ“¡ API Endpoints

### Health Check
```http
GET http://localhost:5000/
```

**Response:**
```json
{
  "status": "running",
  "message": "MediSense AI Backend API",
  "version": "1.0.0",
  "model_loaded": true
}
```

### Predict Disease
```http
POST http://localhost:5000/predict
Content-Type: application/json

{
  "symptoms": ["fever", "cough", "sore throat"]
}
```

**Response:**
```json
[
  {
    "disease": "Flu",
    "confidence": 85.5,
    "matchedSymptoms": 3,
    "totalSymptoms": 9,
    "recommendations": [
      "Rest and avoid physical exertion",
      "Stay home to prevent spreading",
      "Drink plenty of fluids"
    ],
    "medications": [
      "Antiviral medications (Tamiflu, Relenza)",
      "Acetaminophen or Ibuprofen for fever"
    ]
  },
  {
    "disease": "Common Cold",
    "confidence": 72.3,
    "...": "..."
  }
]
```

### Get All Symptoms
```http
GET http://localhost:5000/symptoms
```

### Get All Diseases
```http
GET http://localhost:5000/diseases
```

### Get Disease Details
```http
GET http://localhost:5000/disease/flu
```

## ğŸ”— Frontend Integration

Update `script.js` to use the backend API:

```javascript
// Replace the predictDisease function
async function predictDisease(symptoms) {
  try {
    const response = await fetch('http://localhost:5000/predict', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ symptoms })
    });
    
    if (!response.ok) {
      throw new Error('Prediction failed');
    }
    
    return await response.json();
  } catch (error) {
    console.error('API Error:', error);
    // Fallback to mock predictions
    return mockPredictDisease(symptoms);
  }
}
```

## ğŸ¤– ML Model Details

### Algorithm: Random Forest Classifier

**Why Random Forest?**
- âœ… Handles multi-class classification well
- âœ… Robust to overfitting
- âœ… Provides probability scores
- âœ… Works well with small-medium datasets
- âœ… Fast prediction time

### Feature Engineering

**TF-IDF Vectorization:**
- Converts symptom text to numerical features
- Captures symptom importance
- Uses unigrams and bigrams (1-2 word combinations)
- 200 features max for efficiency

### Model Parameters

```python
RandomForestClassifier(
    n_estimators=100,      # 100 decision trees
    max_depth=20,          # Prevent overfitting
    min_samples_split=5,   # Minimum samples for split
    random_state=42,       # Reproducibility
    n_jobs=-1              # Use all CPU cores
)
```

## ğŸ“Š Dataset Overview

### 24 Diseases Included

**Respiratory:**
- Common Cold, Flu, Pneumonia, Bronchitis, Asthma

**Gastrointestinal:**
- Gastroenteritis, Food Poisoning, Acid Reflux, IBS

**Neurological:**
- Migraine, Tension Headache

**Cardiovascular:**
- Hypertension, Angina

**Metabolic:**
- Diabetes, Hypoglycemia

**Mental Health:**
- Anxiety, Depression

**Infections:**
- UTI, Strep Throat

**Musculoskeletal:**
- Arthritis, Fibromyalgia

**Skin:**
- Eczema, Psoriasis

### Sample Counts
- **Training samples**: 120 (5 per disease)
- **Symptoms per disease**: 5-10
- **Features extracted**: ~200

## ğŸ§ª Testing the Backend

### Using curl:

```bash
# Health check
curl http://localhost:5000/

# Predict disease
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"symptoms": ["fever", "cough", "headache"]}'
```

### Using Python:

```python
import requests

response = requests.post('http://localhost:5000/predict',
    json={'symptoms': ['fever', 'cough', 'headache']}
)
print(response.json())
```

## ğŸ“ˆ Improving the Model

### 1. Add More Training Data

Edit `create_dataset.py` to:
- Add more diseases
- Increase samples per disease
- Add more symptom variations

### 2. Try Different Algorithms

In `train_model.py`, try:

```python
# Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
model = GradientBoostingClassifier(n_estimators=100)

# Neural Network
from sklearn.neural_network import MLPClassifier
model = MLPClassifier(hidden_layer_sizes=(100, 50))

# Support Vector Machine
from sklearn.svm import SVC
model = SVC(kernel='rbf', probability=True)
```

### 3. Hyperparameter Tuning

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

## ğŸ”’ Production Considerations

### Security
- Add API authentication (API keys)
- Rate limiting
- Input validation
- HTTPS encryption

### Scalability
- Use production WSGI server (Gunicorn, uWSGI)
- Add caching (Redis)
- Load balancing
- Database for logging

### Monitoring
- Log all predictions
- Track model performance
- Monitor API usage
- Set up alerts

## ğŸ› Troubleshooting

### Model not loading?
- Run `python create_dataset.py` first
- Then run `python train_model.py`
- Check `model/` directory exists

### CORS errors?
- Make sure Flask-CORS is installed
- Backend must be running on localhost:5000

### Low accuracy?
- Add more training data
- Try different algorithms
- Tune hyperparameters
- Check data quality

## ğŸ“š Next Steps

1. âœ… Install dependencies
2. âœ… Generate dataset
3. âœ… Train model
4. âœ… Start backend server
5. â¬œ Update frontend to use API
6. â¬œ Test end-to-end flow
7. â¬œ Deploy to production

---

**Ready to go!** Your ML-powered disease prediction backend is set up and ready to integrate with the frontend. ğŸš€
